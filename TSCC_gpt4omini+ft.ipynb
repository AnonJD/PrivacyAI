{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Load input texts and ground truth labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parse_entities import *\n",
    "import pandas as pd\n",
    "import json\n",
    "model = '[Your model here]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(text_list:List[str], identifier_list:List[str],store_directory:str)-> None: \n",
    "    system_prompt =  \"You are an expert in labeling Personally Identifiable Information. Start your response rightaway without adding any prefix(such as Response:) and suffix\"\n",
    "    ins_prompt = 'Label the entity of the following text: use @@@,### to label name\\n'\n",
    "    model= model\n",
    "    try:\n",
    "        os.makedirs(store_directory, exist_ok=True)\n",
    "        print(f\"Directory '{store_directory}' is ready.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating directory '{store_directory}': {e}\")\n",
    "    res = []\n",
    "    for i in range(len(text_list)): \n",
    "        request = {\"custom_id\": f'{identifier_list[i]}', \"method\": \"POST\", \n",
    "                  \"url\": \"/v1/chat/completions\", \n",
    "                  \"body\": {\"model\": model, \"messages\": [{\"role\": \"system\", \"content\": system_prompt},{\"role\": \"user\", \"content\": ins_prompt + text_list[i]}],\n",
    "                  \"temperature\":0}}\n",
    "        res.append(request)\n",
    "    \n",
    "    store_directory += '/batch_request.jsonl'\n",
    "    with open(store_directory, 'w',encoding='utf-8') as f:\n",
    "        for entry in res:\n",
    "            json_line = json.dumps(entry, ensure_ascii=False)\n",
    "            f.write(json_line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('new_texts.txt', 'r') as f:\n",
    "    input_texts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide the directory to store the temporary files\n",
    "gpt_storage_directory = \"gpt_output_gpt4omini+ft\"\n",
    "\n",
    "identifier_list = [f'doc{i}' for i in range(len(input_texts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'gpt_output_gpt4omini+ft' is ready.\n",
      "Batch(id='batch_67444c25efac8190a3e9399cae8e3ca2', completion_window='24h', created_at=1732529190, endpoint='/v1/chat/completions', input_file_id='file-XMpFRyEmWvdiq3RAMkAH7E', object='batch', status='validating', cancelled_at=None, cancelling_at=None, completed_at=None, error_file_id=None, errors=None, expired_at=None, expires_at=1732615590, failed_at=None, finalizing_at=None, in_progress_at=None, metadata={'description': 'nightly eval job'}, output_file_id=None, request_counts=BatchRequestCounts(completed=0, failed=0, total=0))\n"
     ]
    }
   ],
   "source": [
    "#make batch file for submitting finetune job \n",
    "make_batch(input_texts, identifier_list,gpt_storage_directory)\n",
    "\n",
    "#submit finetune job \n",
    "submit_finetune_job(gpt_storage_directory)\n",
    "\n",
    "#print the progress\n",
    "check_progress(gpt_storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check progress, if completed, then retrieve the file_id\n",
    "out_id = check_progress(gpt_storage_directory)\n",
    "if out_id != None: \n",
    "    #if comleted, retrieve the result and store the result in a file.\n",
    "    file_response = client.files.content(out_id)\n",
    "    save_file_response_as_jsonl(file_response, gpt_storage_directory)  \n",
    "    data_list = read_jsonl_file(gpt_storage_directory)\n",
    "    data = resort_data(data_list,identifier_list)\n",
    "    batch_extract_parse_store(data,identifier_list,gpt_storage_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_entities = extract_entities(r'gpt_output_gpt4omini+ft/gpt_result.json')\n",
    "detected_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(detected_entities, columns=['file_idx', 'entity_text', 'positions'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as results/TSCC_detected_gpt4omini+ft.csv\n"
     ]
    }
   ],
   "source": [
    "output_file = 'results/TSCC_detected_gpt4omini+ft.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"CSV file saved as {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
